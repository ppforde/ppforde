{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crappy Gifts\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:**\n",
    "\n",
    "Make your own dataset to understand structured queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# datetime libraries\n",
    "import datetime\n",
    "from datetime import time\n",
    "\n",
    "# assign current date and time\n",
    "current_date = datetime.date.today()\n",
    "current_time = datetime.datetime.now()\n",
    "\n",
    "# check datetime information\n",
    "print('Current datetime is',current_time)\n",
    "print('Today is', datetime.datetime.strftime(current_date, '%A, %m/%d/%Y'))\n",
    "print('The time is', datetime.datetime.strftime(current_time, '%I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Fake Reference Data\n",
    "\n",
    "Structures based on your business reporting requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_id = [41, 42, 43, 44, 45]\n",
    "dept_name = ['Electronics', 'Housewares', 'Foodstuffs', 'Clothing', 'Toys']\n",
    "\n",
    "ddf = pd.DataFrame(zip(dept_id, dept_name),\n",
    "                   columns=['dept_id', 'dept_name'])\n",
    "\n",
    "ddf.to_csv('deparments.csv',index=None)\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = []\n",
    "\n",
    "for x in range(635, 646):\n",
    "    product_id.append(x)\n",
    "    \n",
    "product_name = ['Blinking Robot', '27in televsion', 'Laptop', '8 x 10 Rug', '14pc Cutlery Set',\n",
    "                'Stuffed Alien - Grey', 'Mint Creme Cookies', 'Kale Chips', 'Baseball Caps',\n",
    "                'Shoes', 'XL Hoodies']\n",
    "depts = [45, 41, 41, 42, 42, 45, 43, 43, 44, 44, 44]\n",
    "\n",
    "pdf = pd.DataFrame(zip(product_id, product_name, depts),\n",
    "                   columns=['product_id', 'product_name', 'dept_id'])\n",
    "\n",
    "pdf.to_csv('products.csv', index=None)\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = [x for x in range(635, 646)]\n",
    "product_price = [10, 500, 299, 100, 80, 25, 15, 18, 13, 21 ,65]\n",
    "product_margin = [round(random.random(),4) for x in range(len(product_price))]\n",
    "\n",
    "rdf = pd.DataFrame(zip(product_id, product_price, product_margin),\n",
    "                   columns=['product_id', 'product_price', 'product_margin'])\n",
    "\n",
    "rdf.to_csv('prices.csv', index=None)\n",
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_id =  [x for x in range(1,11)]\n",
    "employee_fname = ['Aiden', 'Khalessi', 'Unique', 'Hattie', 'Jes', 'Kira', 'Pat', 'Leslie', 'Jill', 'Adam']\n",
    "employee_location = ['NY', 'TX', 'CA', 'CA', 'OH', 'OH', 'OH', 'OH', 'MI', 'PR']\n",
    "\n",
    "edf = pd.DataFrame(zip(employee_id, employee_fname, employee_location),\n",
    "                   columns=['employee_id', 'employee_fname', 'employee_location'])\n",
    "\n",
    "edf.to_csv('employees.csv', index=None)\n",
    "edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = (\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT',\n",
    "    'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN',\n",
    "    'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA',\n",
    "    'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV',\n",
    "    'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH',\n",
    "    'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN',\n",
    "    'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI',\n",
    "    'WY', 'PR', 'GU', 'VI', 'AS', 'MP', 'DC',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [\n",
    "    'SHLD', 'AMD', 'COG', 'HMC', 'PFE', 'KO', 'FANG', 'NVS',\n",
    "    'ULTA', 'ALK', 'TM', 'BUD', 'CXO', 'ACN', 'MA', 'WHR',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Real Reference Data\n",
    "\n",
    "Using generally accepted structure from external data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states master data\n",
    "# includes District of Columbia\n",
    "# includes four US territories (GU, VI, AS, MP)\n",
    "\n",
    "fips = (1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
    "        25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
    "        44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 72, 66, 78, 60, 69, 11)\n",
    "\n",
    "abbr = ('AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI',\n",
    "        'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI',\n",
    "        'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC',\n",
    "        'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT',\n",
    "        'VT', 'VA', 'WA', 'WV', 'WI', 'WY', 'PR', 'GU', 'VI', 'AS', 'MP',\n",
    "        'DC')\n",
    "\n",
    "regs = ('South', 'West', 'West', 'South', 'West', 'West', 'Northeast', 'South', 'South', 'South',\n",
    "        'West', 'West', 'Midwest', 'Midwest', 'Midwest', 'Midwest', 'South', 'South', 'Northeast',\n",
    "        'South', 'Northeast', 'Midwest', 'Midwest', 'South', 'Midwest', 'West', 'Midwest', 'West',\n",
    "        'Northeast', 'Northeast', 'West', 'Northeast', 'South', 'Midwest', 'Midwest', 'South',\n",
    "        'West', 'Northeast', 'Northeast', 'South', 'Midwest', 'South', 'South', 'West', 'Northeast',\n",
    "        'South', 'West', 'South', 'Midwest', 'West', 'South', 'South', 'South', 'South', 'South',\n",
    "        'South')\n",
    "\n",
    "divs = ('East South Central', 'Pacific', 'Mountain', 'West South Central', 'Pacific',\n",
    "        'Mountain', 'New England', 'South Atlantic', 'South Atlantic', 'South Atlantic',\n",
    "        'Pacific', 'Mountain', 'East North Central', 'East North Central', 'West North Central',\n",
    "        'West North Central', 'East South Central', 'West South Central', 'New England',\n",
    "        'South Atlantic', 'New England', 'East North Central', 'West North Central', \n",
    "        'East South Central', 'West North Central', 'Mountain', 'West North Central', 'Mountain',\n",
    "        'New England', 'Middle Atlantic', 'Mountain', 'Middle Atlantic', 'South Atlantic',\n",
    "        'West North Central', 'East North Central', 'West South Central', 'Pacific',\n",
    "        'Middle Atlantic', 'New England', 'South Atlantic', 'West North Central',\n",
    "        'East South Central', 'West South Central', 'Mountain', 'New England',\n",
    "        'South Atlantic', 'Pacific', 'South Atlantic', 'East North Central', 'Mountain',\n",
    "        'South Atlantic', 'Pacific','South Atlantic', 'Pacific', 'Pacific',\n",
    "        'South Atlantic')\n",
    "\n",
    "seat = (7, 1, 9, 4, 53, 7, 5, 1, 27, 14, 2, 2, 18, 9, 4, 4, 6, 6, 2, 8, 9, 14,\n",
    "        8, 4, 8, 1, 3, 4, 2, 12, 3, 27, 13, 1, 16, 5, 5, 18, 2, 7, 1, 9, 36, 4,\n",
    "        1, 11, 10, 3, 8, 1, 0, 0, 0, 0, 0, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'statefp': fips,\n",
    "        'location_id': abbr,\n",
    "        'region': regs,\n",
    "        'division': divs,\n",
    "        'seats':seat,\n",
    "    }\n",
    ")\n",
    "\n",
    "states_df.info()\n",
    "\n",
    "states_df.to_csv('usstates.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www2.census.gov/geo/docs/reference/cenpop2010/CenPop2010_Mean_ST.txt'\n",
    "\n",
    "census2010 = pd.read_csv(URL)\n",
    "\n",
    "census2010.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make column names lowercase and replace any spaces\n",
    "\n",
    "census2010.columns = census2010.columns.str.lower().str.replace(\" \",\"\")\n",
    "\n",
    "census2010.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Transaction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date, end_date = '2010-01-01', '2021-01-01'\n",
    "\n",
    "current_date = datetime.datetime.now()\n",
    "\n",
    "N = 12000\n",
    "\n",
    "\n",
    "tdf = pd.DataFrame(\n",
    "    \n",
    "    {\n",
    "        'trans_date':np.random.choice(np.arange(start_date, end_date, dtype='datetime64[D]'), size=N),\n",
    "        'product_id':np.random.choice(product_id, size=(N,)),\n",
    "        'location_id':np.random.choice(locations, size=(N,)),\n",
    "        'employee_id':np.random.choice(employee_id, size=(N,)),\n",
    "        'client_id':np.random.choice(clients, size=(N,)),\n",
    "        'sales_hrs':np.random.choice(np.arange(1,17,1, dtype='int64'), size=N),\n",
    "        'sales_tot':np.random.normal(loc=1000, scale=20, size=N).round(2)\n",
    "    }\n",
    "    \n",
    ")\n",
    "\n",
    "tdf['docs_date'] = current_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tdf['forecasts'] = np.where(tdf['trans_date'] <= current_date, False, True)\n",
    "tdf.loc[tdf['trans_date'].dt.year == 2015, ['sales_tot']] = tdf['sales_tot'] * .65\n",
    "\n",
    "tdf.dropna(axis=0, inplace=True)\n",
    "\n",
    "tdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.to_csv('transactions.csv', index=None)\n",
    "tdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crappy_gifts = tdf.merge(pdf).merge(rdf).merge(ddf).merge(edf).merge(states_df).merge(census2010)\n",
    "crappy_gifts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crappy_gifts.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crappy_gifts.to_excel(\"crappy_gifts_usa.xlsx\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

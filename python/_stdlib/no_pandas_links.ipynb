{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Library Review\n",
    "\n",
    "Realizing the power of Python's standard library\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# check system information\n",
    "print('Python Information', sys.version)\n",
    "print('This is your current directory', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime libraries\n",
    "import datetime\n",
    "\n",
    "# assgin current date and time\n",
    "currentDate = datetime.date.today()\n",
    "currentTime = datetime.datetime.now()\n",
    "\n",
    "# check datetime information\n",
    "print('Today is {}'.format(currentDate))\n",
    "print('Today is', datetime.datetime.strftime(currentDate, '%m/%d/%Y'))\n",
    "print('The time is', datetime.datetime.strftime(currentTime, '%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import gzip\n",
    "import glob\n",
    "import csv\n",
    "import shutil\n",
    "import re\n",
    "import random\n",
    "import heapq\n",
    "import sqlite3\n",
    "\n",
    "import collections as clt\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Alternative Fuel Stations](#Alternative-Fuel-Stations)\n",
    "1. [Loans](#Loans)\n",
    "1. [Baby Names](#Baby-Names)\n",
    "1. [Crappy Gifts](#Crappy-Gifts)\n",
    "1. [Solar Power](#Solar-Power)\n",
    "1. [USA](#USA)\n",
    "1. [Census Estimates](#Census-Estimates)\n",
    "1. [IMDB](#IMDB)\n",
    "1. [Yahoo Finance](#Yahoo-Finance)\n",
    "1. [Gutenburg](#Gutenburg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Fuel Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://data.ny.gov/api/views/bpkx-gmh7/rows.csv?accessType=DOWNLOAD&sorting=true'\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `open`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE, \"r\") as f:\n",
    "    header = f.readline()\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = [x for x in data if \"tesla\" in x.lower()]\n",
    "len(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=\"tesla_list.csv\", mode=\"w\") as f:\n",
    "    f.write(header)\n",
    "    f.writelines(tesla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `csv.DictReader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=FILE, mode=\"r\") as csvfile:    \n",
    "    data = list(csv.DictReader(csvfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = [row for row in data if 'tesla' in row['Station Name'].lower()]\n",
    "\n",
    "len(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = list(tesla[0].keys())\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tesla_dict.csv', 'w', newline=\"\", encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = \"tesla_list.csv\"\n",
    "target_file = \"tesla_dict.csv\"\n",
    "\n",
    "\n",
    "with open(source_file, mode='r') as f1:\n",
    "    data1 = f1.readlines()[1:]\n",
    "\n",
    "with open(target_file, mode='r') as f2:\n",
    "    data2 = f2.readlines()[1:]\n",
    "\n",
    "data1 == data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data2).symmetric_difference(set(data1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loan_func(present_value, number_periods, interest_rate):\n",
    "    interest_rate = interest_rate/100/12\n",
    "    return round(interest_rate * present_value / (1-(1+interest_rate)** -number_periods),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Auto\n",
    "print(loan_func(25515, 72, 3.19))\n",
    "\n",
    "# Mortgage\n",
    "print(loan_func(398153, 360, 4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = 3.7\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%m/%d/%Y\")\n",
    "\n",
    "auto = [\n",
    "    {'Present Value':pv,\n",
    "     'Number of Periods':np,\n",
    "     'Interest Rate':ir,\n",
    "     'Monthly Payment':loan_func(pv, np, ir),\n",
    "     'Document Date': current_date,\n",
    "    } for pv in range(22000, 30000, 1000) for np in range(12,84,12)\n",
    "]\n",
    "\n",
    "print(len(auto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in random.choices(auto, k=4):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = 2.6\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%m/%d/%Y\")\n",
    "\n",
    "home = [\n",
    "    {'Present Value':pv,\n",
    "     'Number of Periods':np,\n",
    "     'Interest Rate':ir,\n",
    "     'Monthly Payment':loan_func(pv, np, ir),\n",
    "     'Document Date': current_date,\n",
    "    } for pv in range(450000, 510000, 10000) for np in [180, 360]\n",
    "]\n",
    "\n",
    "print(len(home))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in random.choices(home, k=4):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " loans = auto + home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='loans.csv', mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = loans[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del auto\n",
    "del home\n",
    "del loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baby Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to save files\n",
    "print('This is your current directory', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.ssa.gov/oact/babynames/state/namesbystate.zip'\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(FILE, mode='r') as z:\n",
    "    z.extractall(path='BABY_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('BABY_DATA/*.TXT')\n",
    "pprint(files, compact=True, width=80)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names = [line.strip().split(',') for file in files for line in open(file, 'r').readlines()]\n",
    "print(f\"Total records = {len(baby_names):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(row[1] for row in baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names[0][3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in baby_names:\n",
    "    row.extend([row[3][0]])\n",
    "    \n",
    "baby_names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(row[5] for row in baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baby_names[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in baby_names:\n",
    "    row.extend([len(row[3])])\n",
    "    \n",
    "baby_names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(row[-1] for row in baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [row[3] for row in baby_names if row[1] == 'F']\n",
    "\n",
    "Counter(names).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "idy = 0\n",
    "val = 4\n",
    "\n",
    "pivot_data = sorted(set(x[idx] for x in baby_names if 'Greg' in x[idx]))\n",
    "\n",
    "for z in pivot_data:\n",
    "    pivot_totals = []\n",
    "    for name in baby_names:\n",
    "        if (name[idx] == z) & (name[idy] == 'WI'):\n",
    "            pivot_totals.append(int(name[val]))\n",
    "    print(\"{} = {:,}\".format(z, sum(pivot_totals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del baby_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['state_abbr', 'gender', 'birth_year', 'birth_name', 'total']\n",
    "row_dict_list = list()\n",
    "\n",
    "for file in files:\n",
    "    with open(file, mode='r') as f:\n",
    "        for line in f.readlines():\n",
    "            row = line.strip().split(',')\n",
    "            row_dict = dict(zip(header, row))            \n",
    "            row_dict['initial'] = row_dict['birth_name'][0]\n",
    "            row_dict['length'] = len(row_dict['birth_name'])\n",
    "\n",
    "            row_dict_list.append(row_dict)\n",
    "            \n",
    "print(\"Number of records in collection:\", len(row_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in (random.choices(row_dict_list, k=6)):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='baby_names.csv', mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = row_dict_list[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(row_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del row_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crappy Gifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = ['Blinking Robot', '27in televsion', 'Laptop', '8 x 10 Rug',\n",
    "            '14pc Cutlery Set', 'Stuffed Alien - Grey', 'Mint Creme Cookies',\n",
    "            'Kale Chips', 'Baseball Cap', 'Shoes', 'XL Hoodie']\n",
    "\n",
    "employees = ['Hattie', 'Jes', 'Kira']\n",
    "\n",
    "locations = ['NY', 'TX', 'CA', 'OH', 'MI', 'PR']\n",
    "\n",
    "clients = ['ULTA', 'ALK', 'TM', 'BUD', 'CXO', 'ACN', 'MA', 'WHR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2021,1,1)\n",
    "\n",
    "transactions = [\n",
    "    {'product':random.choice(products),\n",
    "     'employee':e,\n",
    "     'location':random.choice(locations),\n",
    "     'client':random.choice(clients),\n",
    "     'quantity':random.randrange(0,1000),\n",
    "     'sales_rate':round(random.random(),2),\n",
    "     'sales_date':(start_date + datetime.timedelta(d)).strftime(format=\"%Y-%m-%d\"),\n",
    "     'sales_total':0,\n",
    "     'check':False,\n",
    "    } for e in employees for d in range(0, 720)\n",
    "]\n",
    "\n",
    "for row in transactions:\n",
    "    row['sales_total'] = round((row['quantity'] * row['sales_rate']),2)\n",
    "    if row['quantity'] > 975:\n",
    "        row['check'] = True            \n",
    "\n",
    "print(len(transactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in random.choices(transactions, k=3):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='crappy_gifts.csv', mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = transactions[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://data.ny.gov/api/views/3x8r-34rs/rows.csv?accessType=DOWNLOAD&sorting=true'\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE, newline=\"\", encoding='utf-8') as f:\n",
    "    solar_data = list(csv.reader(f, delimiter = \",\"))\n",
    "    solar_header = solar_data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nums(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "print(list(map(nums, [5,.5,0.5,'5',5e3,'5e3','five'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(random.choice(solar_data)):\n",
    "    print(i, solar_header[i], \">>>\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, z in enumerate(solar_header):\n",
    "    data_sets = [x[e] for x in solar_data]\n",
    "    print(\"Index # {} for {} has {:,} record(s)\".format(e,z,len(set(data_sets))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(Counter(x[3] for x in solar_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(Counter(x[9] for x in solar_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(Counter(x[9] for x in solar_data if x[3] == 'Oswego'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del solar_header\n",
    "del solar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_json = []\n",
    "\n",
    "with open (FILE, 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    header = reader.fieldnames\n",
    "    for row in reader:\n",
    "        \n",
    "        if row['Project Status'] == 'Complete':\n",
    "        \n",
    "            # split into a list\n",
    "            row['Program Type'] = row['Program Type'].split(\"/\")\n",
    "\n",
    "            #app_list = row['Georeference'].split(\"\\n\")            \n",
    "            #lat = nums(app_list[-1].split(\",\")[0].replace(\"(\",\"\"))\n",
    "            #lon = nums(app_list[-1].split(\",\")[-1].strip().replace(\")\",\"\"))\n",
    "            try:\n",
    "                app_list = re.findall(pattern=\"([-+]?\\d+\\.\\d+\\s[-+]?\\d+\\.\\d+)\", string=row['Georeference'])\n",
    "                addr = app_list[0]\n",
    "                lat = eval(addr.split(\" \")[0])\n",
    "                lon = eval(addr.split(\" \")[-1])\n",
    "                row['Georeference'] = dict(zip(['Address', 'Latitude', 'Longitude'], [addr, lat, lon]))        \n",
    "            except:\n",
    "                row['Georeference'] = dict(zip(['Address', 'Latitude', 'Longitude'], [addr, None, None])) \n",
    "\n",
    "            # covert numeric fields\n",
    "            for col in ['Total Inverter Quantity', 'Total Nameplate kW DC', 'Total PV Module Quantity',\n",
    "                        'Expected KWh Annual Production', 'Project Cost', '$Incentive']:    \n",
    "                row[col] = nums(row[col])\n",
    "                \n",
    "            # replace columns        \n",
    "            row['Incentive'] = row['$Incentive']\n",
    "\n",
    "            # delete column\n",
    "            del row['$Incentive']\n",
    "\n",
    "            solar_json.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(random.choice(solar_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='solar.csv', mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = solar_json[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(solar_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del solar_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = (\n",
    "    1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
    "    25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
    "    44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 72, 66, 78, 60, 69,\n",
    ")\n",
    "\n",
    "stname = (\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
    "    'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas',\n",
    "    'Kentucky', 'Louisiana',  'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
    "    'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey',\n",
    "    'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
    "    'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas',\n",
    "    'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming',\n",
    "    'Puerto Rico', 'Guam', 'U.S. Virgin Islands', 'American Samoa', 'Northern Mariana Islands',\n",
    ")\n",
    "\n",
    "stabbr = (\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI',\n",
    "    'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI',\n",
    "    'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC',\n",
    "    'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT',\n",
    "    'VT', 'VA', 'WA', 'WV', 'WI', 'WY', 'PR', 'GU', 'VI', 'AS', 'MP',\n",
    ")\n",
    "\n",
    "region = (\n",
    "    'South', 'West', 'West', 'South', 'West', 'West', 'Northeast', 'South', 'South', 'South',\n",
    "    'West', 'West', 'Midwest', 'Midwest', 'Midwest', 'Midwest', 'South', 'South', 'Northeast',\n",
    "    'South', 'Northeast', 'Midwest', 'Midwest', 'South', 'Midwest', 'West', 'Midwest', 'West',\n",
    "    'Northeast', 'Northeast', 'West', 'Northeast', 'South', 'Midwest', 'Midwest', 'South',\n",
    "    'West', 'Northeast', 'Northeast', 'South', 'Midwest', 'South', 'South', 'West', 'Northeast',\n",
    "    'South', 'West', 'South', 'Midwest', 'West', 'South', 'South', 'South', 'South', 'South',\n",
    ")\n",
    "\n",
    "division = (\n",
    "    'East South Central', 'Pacific', 'Mountain', 'West South Central', 'Pacific',\n",
    "    'Mountain', 'New England', 'South Atlantic', 'South Atlantic', 'South Atlantic',\n",
    "    'Pacific', 'Mountain', 'East North Central', 'East North Central', 'West North Central',\n",
    "    'West North Central', 'East South Central', 'West South Central', 'New England',\n",
    "    'South Atlantic', 'New England', 'East North Central', 'West North Central', \n",
    "    'East South Central', 'West North Central', 'Mountain', 'West North Central', 'Mountain',\n",
    "    'New England', 'Middle Atlantic', 'Mountain', 'Middle Atlantic', 'South Atlantic',\n",
    "    'West North Central', 'East North Central', 'West South Central', 'Pacific',\n",
    "    'Middle Atlantic', 'New England', 'South Atlantic', 'West North Central',\n",
    "    'East South Central', 'West South Central', 'Mountain', 'New England',\n",
    "    'South Atlantic', 'Pacific', 'South Atlantic', 'East North Central', 'Mountain',\n",
    "    'South Atlantic', 'Pacific','South Atlantic', 'Pacific', 'Pacific',\n",
    ")\n",
    "\n",
    "seats = (\n",
    "    7,1,9,4,53,7,5,1,27,14,2,2,18,9,4,4,6,6,2,8,9,14,\n",
    "    8,4,8,1,3,4,2,12,3,27,13,1,16,5,5,18,2,7,1,9,36,4,\n",
    "    1,11,10,3,8,1,0,0,0,0,0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `Collections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ('st_fips', 'st_name', 'st_abbr', 'st_regs', 'st_divs', 'st_seats')\n",
    "states_data = []\n",
    "\n",
    "for values in zip(fips, stname, stabbr, region, division, seats):\n",
    "    states_data.append(values)\n",
    "    \n",
    "for row in states_data[0:5]:\n",
    "    pprint(clt.OrderedDict(zip(columns, row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `SQLite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnx = sqlite3.connect(\"usa.db\") # create a database file\n",
    "cnx = sqlite3.connect(\":memory:\") # create in memory\n",
    "cnx.isolation_level=None\n",
    "cursor = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DROP TABLE IF EXISTS states_tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = \\\n",
    "\"\"\"\n",
    "CREATE table states_tbl (\n",
    "    st_fips int,\n",
    "    st_name varchar(40),\n",
    "    st_abbr char(2),\n",
    "    st_regs varchar(30),\n",
    "    st_divs varchar(40),\n",
    "    st_seats int\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(stmt)\n",
    "cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = \"?\" * len(states_data[0])\n",
    "fields = ','.join(fields)\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'states_tbl'\n",
    "\n",
    "cursor.executemany(\"INSERT INTO {} {} VALUES ({})\".format(table, columns, fields), states_data)\n",
    "cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stmt = \\\n",
    "\"\"\"\n",
    "SELECT *\n",
    "FROM states_tbl\n",
    "WHERE st_divs LIKE 'West%'\n",
    "\"\"\"\n",
    "\n",
    "results = cursor.execute(stmt)\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = \\\n",
    "\"\"\"\n",
    "SELECT st_regs, st_divs, count(st_seats) totals\n",
    "FROM states_tbl\n",
    "GROUP BY st_regs, st_divs\n",
    "ORDER BY 3 DESC\n",
    "\"\"\"\n",
    "\n",
    "results = cursor.execute(stmt)\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del states_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "URL = f\"http://www2.census.gov/programs-surveys/popest/datasets/2010-{year}/national/totals/nst-est{year}-alldata.csv\"\n",
    "\n",
    "\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE, newline=\"\", encoding='latin-1') as f:\n",
    "    estimate_data = list(csv.reader(f, delimiter = \",\"))\n",
    "    estimate_header = estimate_data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(estimate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(estimate_header):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dict(zip(estimate_header, random.choice(estimate_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, z in enumerate(estimate_header):\n",
    "    data_sets = [x[e] for x in estimate_data]\n",
    "    print(\"Index # {} for {} has {:,} records\".format(e,z,len(set(data_sets))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nums(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "print(list(map(nums, [5,.5,0.5,'5',5e3,'5e3','five'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_header.index(\"POPESTIMATE2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "value = 17\n",
    "\n",
    "pivot_data = sorted(set(x[index] for x in estimate_data))\n",
    "\n",
    "for z in pivot_data:\n",
    "    pivot_totals = []\n",
    "    for x in estimate_data:\n",
    "        if x[index] == z:\n",
    "            pivot_totals.append(nums(x[value]))\n",
    "    print(\"{} = {:,.2f}\".format(z, sum(pivot_totals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_cols = estimate_header[7:18]\n",
    "\n",
    "for p in pivot_cols:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_cols = [x for x in estimate_header if x.startswith(\"POPEST\")]\n",
    "\n",
    "for p in pivot_cols:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('POPESTIMATE2020'[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#periods = {p: pivot_cols[i][-4:]+\"-12-31\" for i, p in enumerate(pivot_cols)}\n",
    "\n",
    "periods = {p: p[-4:]+\"-12-31\" for p in pivot_cols}\n",
    "\n",
    "pprint(periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_json = []\n",
    "\n",
    "with open(FILE) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row['SUMLEV'] == '040':\n",
    "            for columns in pivot_cols:\n",
    "                estimates_json.append(\n",
    "                    dict(                 \n",
    "                        scenario=columns,\n",
    "                        year_end=periods[columns],\n",
    "                        summary_level=row['SUMLEV'],\n",
    "                        location=row['NAME'],\n",
    "                        region=row['REGION'],\n",
    "                        division=row['DIVISION'],\n",
    "                        population=row[columns],\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in random.choices(estimates_json, k=4):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='estimates.csv', mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = estimates_json[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(estimates_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del estimate_data\n",
    "del estimates_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://datasets.imdbws.com/\"\n",
    "\n",
    "with request.urlopen(URL) as f:\n",
    "    web_data = f.read().decode('utf-8')\n",
    "    \n",
    "data_sets = re.findall(pattern=\"(https.*\\.gz)>\", string=web_data)\n",
    "\n",
    "for i, d in enumerate(data_sets):\n",
    "    print(i, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://datasets.imdbws.com/title.basics.tsv.gz'\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(FILE, mode='r') as f_in, open(FILE.replace('.gz',''), mode='wb') as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompressed_file = FILE.replace('.gz','')\n",
    "\n",
    "print(uncompressed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(uncompressed_file, mode='r', newline='', encoding='utf-8') as f:\n",
    "    imdb_data = list(csv.reader(f, delimiter='\\t', quoting=csv.QUOTE_NONE, ))\n",
    "    imdb_header = imdb_data.pop(0)\n",
    "    \n",
    "print(len(imdb_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(imdb_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, z in enumerate(imdb_header):\n",
    "    try:\n",
    "        data_sets = [x[e] for x in imdb_data]\n",
    "        print(\"Index #{} for {} has {:,} records\".format(e, z, len(set(data_sets))))\n",
    "    except:\n",
    "        print(\"Index #{} has a error\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(Counter(x[4] for x in imdb_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(Counter(x[1] for x in imdb_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_wars = [title for title in imdb_data if 'Star Wars' in title[2]]\n",
    "print(len(star_wars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for head, row in zip(imdb_header, random.choice(star_wars)):\n",
    "    print(head, '>>>', row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del imdb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://m.imdb.com/chart/top'\n",
    "\n",
    "with request.urlopen(URL) as f:\n",
    "    web_data = f.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = re.findall(pattern=\"(tt\\d+)\", string=web_data)\n",
    "\n",
    "movie_titles = set(movie_titles)\n",
    "\n",
    "pprint(movie_titles, compact=True, width=132)\n",
    "print()\n",
    "print(len(movie_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(uncompressed_file, mode='r', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    \n",
    "    with open('imdb_titles.csv', mode='w', newline='', encoding='utf-8')as fw:\n",
    "        fieldnames = reader.fieldnames\n",
    "        writer = csv.DictWriter(fw, dialect='excel', fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            if (row['isAdult'] == '0') & (row['tconst'] in movie_titles):\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=\"https://query1.finance.yahoo.com/v7/finance/download/GTEC?period1=1605828807&period2=1637364807&interval=1d&events=history&includeAdjustedClose=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dates = re.findall(pattern=\"period[\\d]=(\\d+)\", string=URL)\n",
    "data_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.fromtimestamp(int(data_dates[0])).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.fromtimestamp(int(data_dates[1])).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now() - datetime.datetime(1970,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(datetime.datetime.now() - datetime.datetime(1970,1,1)).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=(datetime.datetime.now() - datetime.datetime(1970,1,1)).total_seconds()\n",
    "datetime.datetime.fromtimestamp(d1).strftime(format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=(datetime.datetime.now() - datetime.timedelta(90) - datetime.datetime(1970,1,1)).total_seconds()\n",
    "datetime.datetime.fromtimestamp(d2).strftime(format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period1 = int((datetime.datetime.now() - datetime.timedelta(90) - datetime.datetime(1970,1,1)).total_seconds())\n",
    "period2 = int((datetime.datetime.now() - datetime.datetime(1970,1,1)).total_seconds())\n",
    "\n",
    "print(period1, period2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'AMD'\n",
    "FILE = f\"{symbol}.csv\"\n",
    "URL = f\"https://query1.finance.yahoo.com/v7/finance/download/{symbol}?period1={period1}&period2={period2}&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "\n",
    "print(FILE)\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = list()\n",
    "\n",
    "with open(FILE, \"r\") as f:\n",
    "    headers = f.readline().strip().split(\",\")\n",
    "    for line in f.readlines():\n",
    "        row = line.strip().split(\",\")\n",
    "        row_dict = dict(zip(headers, row))\n",
    "        row_dict['Volume'] = int(row_dict['Volume'])\n",
    "        for c in ['Open','Close', 'High', 'Low', 'Adj Close']:\n",
    "            #row_dict[c] = round(float(row_dict[c]), 2)\n",
    "            row_dict[c] = eval(row_dict[c])\n",
    "        stock.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(stock[:3], width=80, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(stock[-3:], width=80, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = [x['Adj Close'] for x in stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = heapq.nlargest(5, prices)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_days = [x for x in stock if x['Adj Close'] in best]\n",
    "best_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst = heapq.nsmallest(5, prices)\n",
    "worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_days = [x for x in stock if x['Adj Close'] in worst]\n",
    "worst_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gutenburg\n",
    "\n",
    "What are some interesting books to read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'http://www.gutenberg.org/cache/epub/5061/pg5061.txt'\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE, encoding='utf8') as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(data[0:20]):\n",
    "    print(i, line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(data):\n",
    "    if \"Tiny Tim\" in line:\n",
    "        print(i, \"->\", line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE, encoding='utf8') as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(data[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = re.findall('\\w{10,}', data.lower())\n",
    "Counter(words).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(pattern, string):\n",
    "    patt = re.compile(pattern)\n",
    "    matches = patt.finditer(string)    \n",
    "    return list(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny Tim?\n",
    "for d in regex(r'Tiny Tim', data):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sentences with \"Tiny Tim\"\n",
    "get_sentence = re.findall(r\"[^.]*Tiny Tim[^.]*\\.\", data)\n",
    "\n",
    "print(len(get_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in get_sentence:\n",
    "    print(sentence.strip())\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

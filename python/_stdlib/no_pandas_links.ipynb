{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Library Review\n",
    "\n",
    "Realizing the power of Python's standard library\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Information 3.8.3 (default, Jul  2 2020, 16:21:59) \n",
      "[GCC 7.3.0]\n",
      "This is your current directory /home/gda/Documents/github/ppforde/python/_stdlib\n"
     ]
    }
   ],
   "source": [
    "# system libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# check system information\n",
    "print('Python Information', sys.version)\n",
    "print('This is your current directory', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 2021-12-26\n",
      "Today is 12/26/2021\n",
      "The time is 09:28:19\n"
     ]
    }
   ],
   "source": [
    "# datetime libraries\n",
    "import datetime\n",
    "\n",
    "# assgin current date and time\n",
    "currentDate = datetime.date.today()\n",
    "currentTime = datetime.datetime.now()\n",
    "\n",
    "# check datetime information\n",
    "print('Today is {}'.format(currentDate))\n",
    "print('Today is', datetime.datetime.strftime(currentDate, '%m/%d/%Y'))\n",
    "print('The time is', datetime.datetime.strftime(currentTime, '%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import gzip\n",
    "import glob\n",
    "import csv\n",
    "import shutil\n",
    "import re\n",
    "import random\n",
    "import heapq\n",
    "import sqlite3\n",
    "\n",
    "import collections as clt\n",
    "\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Alternative Fuel Stations](#Alternative-Fuel-Stations)\n",
    "1. [Loans](#Loans)\n",
    "1. [Baby Names](#Baby-Names)\n",
    "1. [Crappy Gifts](#Crappy-Gifts)\n",
    "1. [Solar Power](#Solar-Power)\n",
    "1. [USA](#USA)\n",
    "1. [Census Estimates](#Census-Estimates)\n",
    "1. [IMDB](#IMDB)\n",
    "1. [Yahoo Finance](#Yahoo-Finance)\n",
    "1. [Gutenburg](#Gutenburg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Fuel Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://data.ny.gov/api/views/bpkx-gmh7/rows.csv?accessType=DOWNLOAD&sorting=true'\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `open`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE, \"r\") as f:\n",
    "    header = f.readline()\n",
    "    data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = [x for x in data if \"tesla\" in x.lower()]\n",
    "len(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=\"tesla_list.csv\", mode=\"w\") as f:\n",
    "    f.write(header)\n",
    "    f.writelines(tesla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `csv.DictReader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=FILE, mode=\"r\") as csvfile:    \n",
    "    data = list(csv.DictReader(csvfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = [row for row in data if 'tesla' in row['Station Name'].lower()]\n",
    "\n",
    "len(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = list(tesla[0].keys())\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tesla_dict.csv', 'w', newline=\"\", encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = \"tesla_list.csv\"\n",
    "target_file = \"tesla_dict.csv\"\n",
    "\n",
    "\n",
    "with open(source_file, mode='r') as f1:\n",
    "    data1 = f1.readlines()[1:]\n",
    "\n",
    "with open(target_file, mode='r') as f2:\n",
    "    data2 = f2.readlines()[1:]\n",
    "\n",
    "data1 == data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data2).symmetric_difference(set(data1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loan_func(present_value, number_periods, interest_rate):\n",
    "    interest_rate = interest_rate/100/12\n",
    "    return round(interest_rate * present_value / (1-(1+interest_rate)** -number_periods),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Auto\n",
    "print(loan_func(25515, 72, 3.19))\n",
    "\n",
    "# Mortgage\n",
    "print(loan_func(398153, 360, 4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = 3.7\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%m/%d/%Y\")\n",
    "\n",
    "auto = [\n",
    "    {'Present Value':pv,\n",
    "     'Number of Periods':np,\n",
    "     'Interest Rate':ir,\n",
    "     'Monthly Payment':loan_func(pv, np, ir),\n",
    "     'Document Date': current_date,\n",
    "    } for pv in range(22000, 30000, 1000) for np in range(12,84,12)\n",
    "]\n",
    "\n",
    "print(len(auto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in random.choices(auto, k=4):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = 2.6\n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%m/%d/%Y\")\n",
    "\n",
    "home = [\n",
    "    {'Present Value':pv,\n",
    "     'Number of Periods':np,\n",
    "     'Interest Rate':ir,\n",
    "     'Monthly Payment':loan_func(pv, np, ir),\n",
    "     'Document Date': current_date,\n",
    "    } for pv in range(450000, 510000, 10000) for np in [180, 360]\n",
    "]\n",
    "\n",
    "print(len(home))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in random.choices(home, k=4):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " loans = auto + home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='loans.csv', mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = loans[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del auto\n",
    "del home\n",
    "del loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baby Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to save files\n",
    "print('This is your current directory', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.ssa.gov/oact/babynames/state/namesbystate.zip'\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(FILE, mode='r') as z:\n",
    "    z.extractall(path='BABY_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('BABY_DATA/*.TXT')\n",
    "pprint(files, compact=True, width=80)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names = [line.strip().split(',') for file in files for line in open(file, 'r').readlines()]\n",
    "print(f\"Total records = {len(baby_names):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(row[1] for row in baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_names[0][3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in baby_names:\n",
    "    row.extend([row[3][0]])\n",
    "    \n",
    "baby_names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(row[5] for row in baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baby_names[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in baby_names:\n",
    "    row.extend([len(row[3])])\n",
    "    \n",
    "baby_names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(row[-1] for row in baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [row[3] for row in baby_names if row[1] == 'F']\n",
    "\n",
    "Counter(names).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "idy = 0\n",
    "val = 4\n",
    "\n",
    "pivot_data = sorted(set(x[idx] for x in baby_names if 'Greg' in x[idx]))\n",
    "\n",
    "for z in pivot_data:\n",
    "    pivot_totals = []\n",
    "    for name in baby_names:\n",
    "        if (name[idx] == z) & (name[idy] == 'WI'):\n",
    "            pivot_totals.append(int(name[val]))\n",
    "    print(\"{} = {:,}\".format(z, sum(pivot_totals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del baby_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['state_abbr', 'gender', 'birth_year', 'birth_name', 'total']\n",
    "row_dict_list = list()\n",
    "\n",
    "for file in files:\n",
    "    with open(file, mode='r') as f:\n",
    "        for line in f.readlines():\n",
    "            row = line.strip().split(',')\n",
    "            row_dict = dict(zip(header, row))            \n",
    "            row_dict['initial'] = row_dict['birth_name'][0]\n",
    "            row_dict['length'] = len(row_dict['birth_name'])\n",
    "\n",
    "            row_dict_list.append(row_dict)\n",
    "            \n",
    "print(\"Number of records in collection:\", len(row_dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in (random.choices(row_dict_list, k=6)):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='baby_names.csv', mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = row_dict_list[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(row_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del row_dict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crappy Gifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = ['Blinking Robot', '27in televsion', 'Laptop', '8 x 10 Rug',\n",
    "            '14pc Cutlery Set', 'Stuffed Alien - Grey', 'Mint Creme Cookies',\n",
    "            'Kale Chips', 'Baseball Cap', 'Shoes', 'XL Hoodie']\n",
    "\n",
    "employees = ['Hattie', 'Jes', 'Kira']\n",
    "\n",
    "locations = ['NY', 'TX', 'CA', 'OH', 'MI', 'PR']\n",
    "\n",
    "clients = ['ULTA', 'ALK', 'TM', 'BUD', 'CXO', 'ACN', 'MA', 'WHR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2021,1,1)\n",
    "\n",
    "transactions = [\n",
    "    {'product':random.choice(products),\n",
    "     'employee':e,\n",
    "     'location':random.choice(locations),\n",
    "     'client':random.choice(clients),\n",
    "     'quantity':random.randrange(0,1000),\n",
    "     'sales_rate':round(random.random(),2),\n",
    "     'sales_date':(start_date + datetime.timedelta(d)).strftime(format=\"%Y-%m-%d\"),\n",
    "     'sales_total':0,\n",
    "     'check':False,\n",
    "    } for e in employees for d in range(0, 720)\n",
    "]\n",
    "\n",
    "for row in transactions:\n",
    "    row['sales_total'] = round((row['quantity'] * row['sales_rate']),2)\n",
    "    if row['quantity'] > 975:\n",
    "        row['check'] = True            \n",
    "\n",
    "print(len(transactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in random.choices(transactions, k=3):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='crappy_gifts.csv', mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = transactions[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://data.ny.gov/api/views/3x8r-34rs/rows.csv?accessType=DOWNLOAD&sorting=true'\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE, newline=\"\", encoding='utf-8') as f:\n",
    "    solar_data = list(csv.reader(f, delimiter = \",\"))\n",
    "    solar_header = solar_data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nums(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "print(list(map(nums, [5,.5,0.5,'5',5e3,'5e3','five'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(random.choice(solar_data)):\n",
    "    print(i, solar_header[i], \">>>\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, z in enumerate(solar_header):\n",
    "    data_sets = [x[e] for x in solar_data]\n",
    "    print(\"Index # {} for {} has {:,} record(s)\".format(e,z,len(set(data_sets))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(Counter(x[3] for x in solar_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(Counter(x[9] for x in solar_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(Counter(x[9] for x in solar_data if x[3] == 'Oswego'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del solar_header\n",
    "del solar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_json = []\n",
    "\n",
    "with open (FILE, 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    header = reader.fieldnames\n",
    "    for row in reader:\n",
    "        \n",
    "        if row['Project Status'] == 'Complete':\n",
    "        \n",
    "            # split into a list\n",
    "            row['Program Type'] = row['Program Type'].split(\"/\")\n",
    "\n",
    "            #app_list = row['Georeference'].split(\"\\n\")            \n",
    "            #lat = nums(app_list[-1].split(\",\")[0].replace(\"(\",\"\"))\n",
    "            #lon = nums(app_list[-1].split(\",\")[-1].strip().replace(\")\",\"\"))\n",
    "            try:\n",
    "                app_list = re.findall(pattern=\"([-+]?\\d+\\.\\d+\\s[-+]?\\d+\\.\\d+)\", string=row['Georeference'])\n",
    "                addr = app_list[0]\n",
    "                lat = eval(addr.split(\" \")[0])\n",
    "                lon = eval(addr.split(\" \")[-1])\n",
    "                row['Georeference'] = dict(zip(['Address', 'Latitude', 'Longitude'], [addr, lat, lon]))        \n",
    "            except:\n",
    "                row['Georeference'] = dict(zip(['Address', 'Latitude', 'Longitude'], [addr, None, None])) \n",
    "\n",
    "            # covert numeric fields\n",
    "            for col in ['Total Inverter Quantity', 'Total Nameplate kW DC', 'Total PV Module Quantity',\n",
    "                        'Expected KWh Annual Production', 'Project Cost', '$Incentive']:    \n",
    "                row[col] = nums(row[col])\n",
    "                \n",
    "            # replace columns        \n",
    "            row['Incentive'] = row['$Incentive']\n",
    "\n",
    "            # delete column\n",
    "            del row['$Incentive']\n",
    "\n",
    "            solar_json.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(random.choice(solar_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='solar.csv', mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = solar_json[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(solar_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del solar_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = (\n",
    "    1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
    "    25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
    "    44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 72, 66, 78, 60, 69,\n",
    ")\n",
    "\n",
    "stname = (\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
    "    'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas',\n",
    "    'Kentucky', 'Louisiana',  'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
    "    'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey',\n",
    "    'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
    "    'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas',\n",
    "    'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming',\n",
    "    'Puerto Rico', 'Guam', 'U.S. Virgin Islands', 'American Samoa', 'Northern Mariana Islands',\n",
    ")\n",
    "\n",
    "stabbr = (\n",
    "    'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI',\n",
    "    'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI',\n",
    "    'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC',\n",
    "    'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT',\n",
    "    'VT', 'VA', 'WA', 'WV', 'WI', 'WY', 'PR', 'GU', 'VI', 'AS', 'MP',\n",
    ")\n",
    "\n",
    "region = (\n",
    "    'South', 'West', 'West', 'South', 'West', 'West', 'Northeast', 'South', 'South', 'South',\n",
    "    'West', 'West', 'Midwest', 'Midwest', 'Midwest', 'Midwest', 'South', 'South', 'Northeast',\n",
    "    'South', 'Northeast', 'Midwest', 'Midwest', 'South', 'Midwest', 'West', 'Midwest', 'West',\n",
    "    'Northeast', 'Northeast', 'West', 'Northeast', 'South', 'Midwest', 'Midwest', 'South',\n",
    "    'West', 'Northeast', 'Northeast', 'South', 'Midwest', 'South', 'South', 'West', 'Northeast',\n",
    "    'South', 'West', 'South', 'Midwest', 'West', 'South', 'South', 'South', 'South', 'South',\n",
    ")\n",
    "\n",
    "division = (\n",
    "    'East South Central', 'Pacific', 'Mountain', 'West South Central', 'Pacific',\n",
    "    'Mountain', 'New England', 'South Atlantic', 'South Atlantic', 'South Atlantic',\n",
    "    'Pacific', 'Mountain', 'East North Central', 'East North Central', 'West North Central',\n",
    "    'West North Central', 'East South Central', 'West South Central', 'New England',\n",
    "    'South Atlantic', 'New England', 'East North Central', 'West North Central', \n",
    "    'East South Central', 'West North Central', 'Mountain', 'West North Central', 'Mountain',\n",
    "    'New England', 'Middle Atlantic', 'Mountain', 'Middle Atlantic', 'South Atlantic',\n",
    "    'West North Central', 'East North Central', 'West South Central', 'Pacific',\n",
    "    'Middle Atlantic', 'New England', 'South Atlantic', 'West North Central',\n",
    "    'East South Central', 'West South Central', 'Mountain', 'New England',\n",
    "    'South Atlantic', 'Pacific', 'South Atlantic', 'East North Central', 'Mountain',\n",
    "    'South Atlantic', 'Pacific','South Atlantic', 'Pacific', 'Pacific',\n",
    ")\n",
    "\n",
    "seats = (\n",
    "    7,1,9,4,53,7,5,1,27,14,2,2,18,9,4,4,6,6,2,8,9,14,\n",
    "    8,4,8,1,3,4,2,12,3,27,13,1,16,5,5,18,2,7,1,9,36,4,\n",
    "    1,11,10,3,8,1,0,0,0,0,0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `Collections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ('st_fips', 'st_name', 'st_abbr', 'st_regs', 'st_divs', 'st_seats')\n",
    "states_data = []\n",
    "\n",
    "for values in zip(fips, stname, stabbr, region, division, seats):\n",
    "    states_data.append(values)\n",
    "    \n",
    "for row in states_data[0:5]:\n",
    "    pprint(clt.OrderedDict(zip(columns, row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `SQLite`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnx = sqlite3.connect(\"usa.db\") # create a database file\n",
    "cnx = sqlite3.connect(\":memory:\") # create in memory\n",
    "cnx.isolation_level=None\n",
    "cursor = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DROP TABLE IF EXISTS states_tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = \\\n",
    "\"\"\"\n",
    "CREATE table states_tbl (\n",
    "    st_fips int,\n",
    "    st_name varchar(40),\n",
    "    st_abbr char(2),\n",
    "    st_regs varchar(30),\n",
    "    st_divs varchar(40),\n",
    "    st_seats int\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(stmt)\n",
    "cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = \"?\" * len(states_data[0])\n",
    "fields = ','.join(fields)\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'states_tbl'\n",
    "\n",
    "cursor.executemany(\"INSERT INTO {} {} VALUES ({})\".format(table, columns, fields), states_data)\n",
    "cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stmt = \\\n",
    "\"\"\"\n",
    "SELECT *\n",
    "FROM states_tbl\n",
    "WHERE st_divs LIKE 'West%'\n",
    "\"\"\"\n",
    "\n",
    "results = cursor.execute(stmt)\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = \\\n",
    "\"\"\"\n",
    "SELECT st_regs, st_divs, count(st_seats) totals\n",
    "FROM states_tbl\n",
    "GROUP BY st_regs, st_divs\n",
    "ORDER BY 3 DESC\n",
    "\"\"\"\n",
    "\n",
    "results = cursor.execute(stmt)\n",
    "\n",
    "for row in results:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del states_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "URL = f\"http://www2.census.gov/programs-surveys/popest/datasets/2010-{year}/national/totals/nst-est{year}-alldata.csv\"\n",
    "\n",
    "\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE, newline=\"\", encoding='latin-1') as f:\n",
    "    estimate_data = list(csv.reader(f, delimiter = \",\"))\n",
    "    estimate_header = estimate_data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(estimate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(estimate_header):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dict(zip(estimate_header, random.choice(estimate_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, z in enumerate(estimate_header):\n",
    "    data_sets = [x[e] for x in estimate_data]\n",
    "    print(\"Index # {} for {} has {:,} records\".format(e,z,len(set(data_sets))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nums(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "print(list(map(nums, [5,.5,0.5,'5',5e3,'5e3','five'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_header.index(\"POPESTIMATE2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "value = 17\n",
    "\n",
    "pivot_data = sorted(set(x[index] for x in estimate_data))\n",
    "\n",
    "for z in pivot_data:\n",
    "    pivot_totals = []\n",
    "    for x in estimate_data:\n",
    "        if x[index] == z:\n",
    "            pivot_totals.append(nums(x[value]))\n",
    "    print(\"{} = {:,.2f}\".format(z, sum(pivot_totals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_cols = estimate_header[7:18]\n",
    "\n",
    "for p in pivot_cols:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_cols = [x for x in estimate_header if x.startswith(\"POPEST\")]\n",
    "\n",
    "for p in pivot_cols:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('POPESTIMATE2020'[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#periods = {p: pivot_cols[i][-4:]+\"-12-31\" for i, p in enumerate(pivot_cols)}\n",
    "\n",
    "periods = {p: p[-4:]+\"-12-31\" for p in pivot_cols}\n",
    "\n",
    "pprint(periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_json = []\n",
    "\n",
    "with open(FILE) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        if row['SUMLEV'] == '040':\n",
    "            for columns in pivot_cols:\n",
    "                estimates_json.append(\n",
    "                    dict(                 \n",
    "                        scenario=columns,\n",
    "                        year_end=periods[columns],\n",
    "                        summary_level=row['SUMLEV'],\n",
    "                        location=row['NAME'],\n",
    "                        region=row['REGION'],\n",
    "                        division=row['DIVISION'],\n",
    "                        population=row[columns],\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in random.choices(estimates_json, k=4):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file='estimates.csv', mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = estimates_json[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(estimates_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del estimate_data\n",
    "del estimates_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://datasets.imdbws.com/\"\n",
    "\n",
    "with request.urlopen(URL) as f:\n",
    "    web_data = f.read().decode('utf-8')\n",
    "    \n",
    "data_sets = re.findall(pattern=\"(https.*\\.gz)>\", string=web_data)\n",
    "\n",
    "for i, d in enumerate(data_sets):\n",
    "    print(i, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://datasets.imdbws.com/title.basics.tsv.gz'\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(FILE, mode='r') as f_in, open(FILE.replace('.gz',''), mode='wb') as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompressed_file = FILE.replace('.gz','')\n",
    "\n",
    "print(uncompressed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(uncompressed_file, mode='r', newline='', encoding='utf-8') as f:\n",
    "    imdb_data = list(csv.reader(f, delimiter='\\t', quoting=csv.QUOTE_NONE, ))\n",
    "    imdb_header = imdb_data.pop(0)\n",
    "    \n",
    "print(len(imdb_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(imdb_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, z in enumerate(imdb_header):\n",
    "    try:\n",
    "        data_sets = [x[e] for x in imdb_data]\n",
    "        print(\"Index #{} for {} has {:,} records\".format(e, z, len(set(data_sets))))\n",
    "    except:\n",
    "        print(\"Index #{} has a error\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(Counter(x[4] for x in imdb_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(Counter(x[1] for x in imdb_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_wars = [title for title in imdb_data if 'Star Wars' in title[2]]\n",
    "print(len(star_wars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for head, row in zip(imdb_header, random.choice(star_wars)):\n",
    "    print(head, '>>>', row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del imdb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://m.imdb.com/chart/top'\n",
    "\n",
    "with request.urlopen(URL) as f:\n",
    "    web_data = f.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = re.findall(pattern=\"(tt\\d+)\", string=web_data)\n",
    "\n",
    "movie_titles = set(movie_titles)\n",
    "\n",
    "pprint(movie_titles, compact=True, width=132)\n",
    "print()\n",
    "print(len(movie_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(uncompressed_file, mode='r', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    \n",
    "    with open('imdb_titles.csv', mode='w', newline='', encoding='utf-8')as fw:\n",
    "        fieldnames = reader.fieldnames\n",
    "        writer = csv.DictWriter(fw, dialect='excel', fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            if (row['isAdult'] == '0') & (row['tconst'] in movie_titles):\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=\"https://query1.finance.yahoo.com/v7/finance/download/GTEC?period1=1605828807&period2=1637364807&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dates = re.findall(pattern=\"period[\\d]=(\\d+)\", string=URL)\n",
    "data_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.fromtimestamp(int(data_dates[0])).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.fromtimestamp(int(data_dates[1])).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now() - datetime.datetime(1970,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(datetime.datetime.now() - datetime.datetime(1970,1,1)).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=(datetime.datetime.now() - datetime.datetime(1970,1,1)).total_seconds()\n",
    "datetime.datetime.fromtimestamp(d1).strftime(format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=(datetime.datetime.now() - datetime.timedelta(90) - datetime.datetime(1970,1,1)).total_seconds()\n",
    "datetime.datetime.fromtimestamp(d2).strftime(format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period1 = int((datetime.datetime.now() - datetime.timedelta(90) - datetime.datetime(1970,1,1)).total_seconds())\n",
    "period2 = int((datetime.datetime.now() - datetime.datetime(1970,1,1)).total_seconds())\n",
    "\n",
    "print(period1, period2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'AMD'\n",
    "FILE = f\"{symbol}.csv\"\n",
    "URL = f\"https://query1.finance.yahoo.com/v7/finance/download/{symbol}?period1={period1}&period2={period2}&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "\n",
    "print(FILE)\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = list()\n",
    "\n",
    "with open(FILE, \"r\") as f:\n",
    "    headers = f.readline().strip().split(\",\")\n",
    "    for line in f.readlines():\n",
    "        row = line.strip().split(\",\")\n",
    "        row_dict = dict(zip(headers, row))\n",
    "        row_dict['Volume'] = int(row_dict['Volume'])\n",
    "        for c in ['Open','Close', 'High', 'Low', 'Adj Close']:\n",
    "            #row_dict[c] = round(float(row_dict[c]), 2)\n",
    "            row_dict[c] = eval(row_dict[c])\n",
    "        stock.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(stock[:3], width=80, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(stock[-3:], width=80, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = [x['Adj Close'] for x in stock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = heapq.nlargest(5, prices)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_days = [x for x in stock if x['Adj Close'] in best]\n",
    "best_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst = heapq.nsmallest(5, prices)\n",
    "worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_days = [x for x in stock if x['Adj Close'] in worst]\n",
    "worst_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gutenburg\n",
    "\n",
    "What are some interesting books to read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.gutenberg.org/cache/epub/19337/pg19337.txt\n",
      "pg19337.txt\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://www.gutenberg.org/cache/epub/19337/pg19337.txt\"\n",
    "FILE = (request.urlsplit(URL).path).split(\"/\")[-1]\n",
    "print(URL)\n",
    "print(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pg19337.txt', <http.client.HTTPMessage at 0x7f29f4667d90>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request.urlretrieve(URL, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "with open(FILE, encoding='utf-8-sig') as f:\n",
    "    data = f.readlines()\n",
    "    \n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3853\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001 >>> The Project Gutenberg EBook of A Christmas Carol, by Charles Dickens\n",
      "0002 >>> \n",
      "0003 >>> This eBook is for the use of anyone anywhere at no cost and with\n",
      "0004 >>> almost no restrictions whatsoever.  You may copy it, give it away or\n",
      "0005 >>> re-use it under the terms of the Project Gutenberg License included\n",
      "0006 >>> with this eBook or online at www.gutenberg.org\n",
      "0007 >>> \n",
      "0008 >>> \n",
      "0009 >>> Title: A Christmas Carol\n",
      "0010 >>> \n",
      "0011 >>> Author: Charles Dickens\n",
      "0012 >>> \n",
      "0013 >>> Illustrator: George Alfred Williams\n",
      "0014 >>> \n",
      "0015 >>> Release Date: September 20, 2006 [EBook #19337]\n",
      "0016 >>> Last updated: January 21, 2009\n",
      "0017 >>> \n",
      "0018 >>> Language: English\n",
      "0019 >>> \n",
      "0020 >>> \n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(data[0:20], start=1):\n",
    "    print(str(i).zfill(4), \">>>\", line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0090 >>> comes that true note of pathos, the ever memorable toast of Tiny Tim,\n",
      "1942 >>> your brother, Tiny Tim? And Martha warn't as late last Christmas-day by\n",
      "1966 >>> seasonable; and Tiny Tim upon his shoulder. Alas for Tiny Tim, he bore a\n",
      "1979 >>> arms, while the two young Cratchits hustled Tiny Tim, and bore him off\n",
      "1995 >>> he said that Tiny Tim was growing strong and hearty.\n",
      "2012 >>> took Tiny Tim beside him in a tiny corner at the table; the two young\n",
      "2020 >>> delight arose all round the board, and even Tiny Tim, excited by the two\n",
      "2075 >>> \"God bless us every one!\" said Tiny Tim, the last of all.\n",
      "2082 >>> me if Tiny Tim will live.\"\n",
      "2129 >>> proceedings which had no heartiness in it. Tiny Tim drank it last of\n",
      "2994 >>> The colour? Ah, poor Tiny Tim!\n",
      "3007 >>> \"I have known him walk with--I have known him walk with Tiny Tim upon\n",
      "3069 >>> delightful. It really seemed as if he had known our Tiny Tim, and felt\n",
      "3094 >>> shall not quarrel easily among ourselves, and forget poor Tiny Tim in\n",
      "3303 >>> size of Tiny Tim. Joe Miller never made such a joke as sending it to\n",
      "3468 >>> and to Tiny Tim, who did NOT die, he was a second father. He became as\n",
      "3484 >>> Tiny Tim observed, God bless Us, Every One!\n"
     ]
    }
   ],
   "source": [
    "for i, line in enumerate(data):\n",
    "    if \"Tiny Tim\" in line:\n",
    "        print(str(i).zfill(4), \">>>\", line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "with open(FILE, encoding='utf-8-sig') as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sessed to a remarkable degree, together with his naturally jovial\\n'\n",
      " 'attitude toward life in general, seem to have given him a remarkably\\n'\n",
      " 'happy feeling toward Christmas, though the privations and hardshi')\n"
     ]
    }
   ],
   "source": [
    "pprint(data[1000:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('electronic', 27),\n",
       " ('foundation', 25),\n",
       " ('everything', 12),\n",
       " ('associated', 10),\n",
       " ('particular', 9),\n",
       " ('information', 8),\n",
       " ('remembered', 7),\n",
       " ('permission', 7),\n",
       " ('distributing', 7),\n",
       " ('distributed', 6),\n",
       " ('especially', 6),\n",
       " ('themselves', 6),\n",
       " ('distribute', 6),\n",
       " ('distribution', 6),\n",
       " ('volunteers', 6),\n",
       " ('illustration', 5),\n",
       " ('remarkable', 5),\n",
       " ('expression', 5),\n",
       " ('characters', 5),\n",
       " ('impossible', 5),\n",
       " ('explanation', 5),\n",
       " ('compliance', 5),\n",
       " ('replacement', 5),\n",
       " ('brightness', 4),\n",
       " ('afterwards', 4)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = re.findall('\\w{10,}', data.lower())\n",
    "Counter(words).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(pattern, string):\n",
    "    patt = re.compile(pattern)\n",
    "    matches = patt.finditer(string)    \n",
    "    return list(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(3074, 3082), match='Tiny Tim'>\n",
      "<re.Match object; span=(91542, 91550), match='Tiny Tim'>\n",
      "<re.Match object; span=(92535, 92543), match='Tiny Tim'>\n",
      "<re.Match object; span=(92572, 92580), match='Tiny Tim'>\n",
      "<re.Match object; span=(93128, 93136), match='Tiny Tim'>\n",
      "<re.Match object; span=(93828, 93836), match='Tiny Tim'>\n",
      "<re.Match object; span=(94826, 94834), match='Tiny Tim'>\n",
      "<re.Match object; span=(95422, 95430), match='Tiny Tim'>\n",
      "<re.Match object; span=(98310, 98318), match='Tiny Tim'>\n",
      "<re.Match object; span=(98629, 98637), match='Tiny Tim'>\n",
      "<re.Match object; span=(100723, 100731), match='Tiny Tim'>\n",
      "<re.Match object; span=(143222, 143230), match='Tiny Tim'>\n",
      "<re.Match object; span=(143738, 143746), match='Tiny Tim'>\n",
      "<re.Match object; span=(146591, 146599), match='Tiny Tim'>\n",
      "<re.Match object; span=(147553, 147561), match='Tiny Tim'>\n",
      "<re.Match object; span=(155937, 155945), match='Tiny Tim'>\n",
      "<re.Match object; span=(163088, 163096), match='Tiny Tim'>\n",
      "<re.Match object; span=(164061, 164069), match='Tiny Tim'>\n"
     ]
    }
   ],
   "source": [
    "# Tiny Tim?\n",
    "for d in regex(r'Tiny Tim', data):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# Get sentences with \"Tiny Tim\"\n",
    "get_sentence = re.findall(r\"[^.]*Tiny Tim[^.]*\\.\", data)\n",
    "\n",
    "print(len(get_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, glorious! Glorious!\" All this\n",
      "brightness has its attendant shadow, and deep from the childish heart\n",
      "comes that true note of pathos, the ever memorable toast of Tiny Tim,\n",
      "\"God bless Us, Every One!\" \"The Cricket on the Hearth\" strikes a\n",
      "different note.\n",
      "--------------------------------------------------------------------------------\n",
      "\"And\n",
      "your brother, Tiny Tim? And Martha warn't as late last Christmas-day by\n",
      "half an hour!\"\n",
      "\n",
      "\"Here's Martha, mother!\" said a girl, appearing as she spoke.\n",
      "--------------------------------------------------------------------------------\n",
      "\"Hide, Martha, hide!\"\n",
      "\n",
      "So Martha hid herself, and in came little Bob, the father, with at least\n",
      "three feet of comforter, exclusive of the fringe, hanging down before\n",
      "him; and his threadbare clothes darned up and brushed to look\n",
      "seasonable; and Tiny Tim upon his shoulder.\n",
      "--------------------------------------------------------------------------------\n",
      "Alas for Tiny Tim, he bore a\n",
      "little crutch, and had his limbs supported by an iron frame!\n",
      "\n",
      "\"Why, where's our Martha?\" cried Bob Cratchit, looking round.\n",
      "--------------------------------------------------------------------------------\n",
      "\"Not coming upon Christmas-day!\"\n",
      "\n",
      "Martha didn't like to see him disappointed, if it were only in joke; so\n",
      "she came out prematurely from behind the closet door, and ran into his\n",
      "arms, while the two young Cratchits hustled Tiny Tim, and bore him off\n",
      "into the wash-house, that he might hear the pudding singing in the\n",
      "copper.\n",
      "--------------------------------------------------------------------------------\n",
      "\"\n",
      "\n",
      "Bob's voice was tremulous when he told them this, and trembled more when\n",
      "he said that Tiny Tim was growing strong and hearty.\n",
      "--------------------------------------------------------------------------------\n",
      "Cratchit made the gravy (ready beforehand in a little saucepan) hissing\n",
      "hot; Master Peter mashed the potatoes with incredible vigour; Miss\n",
      "Belinda sweetened up the apple sauce; Martha dusted the hot plates; Bob\n",
      "took Tiny Tim beside him in a tiny corner at the table; the two young\n",
      "Cratchits set chairs for everybody, not forgetting themselves, and,\n",
      "mounting guard upon their posts, crammed spoons into their mouths, lest\n",
      "they should shriek for goose before their turn came to be helped.\n",
      "--------------------------------------------------------------------------------\n",
      "Cratchit, looking slowly all along the\n",
      "carving-knife, prepared to plunge it in the breast; but when she did,\n",
      "and when the long-expected gush of stuffing issued forth, one murmur of\n",
      "delight arose all round the board, and even Tiny Tim, excited by the two\n",
      "young Cratchits, beat on the table with the handle of his knife, and\n",
      "feebly cried Hurrah!\n",
      "\n",
      "There never was such a goose.\n",
      "--------------------------------------------------------------------------------\n",
      "\"God bless us every one!\" said Tiny Tim, the last of all.\n",
      "--------------------------------------------------------------------------------\n",
      "\"Spirit,\" said Scrooge with an interest he had never felt before, \"tell\n",
      "me if Tiny Tim will live.\n",
      "--------------------------------------------------------------------------------\n",
      "Tiny Tim drank it last of\n",
      "all, but he didn't care twopence for it.\n",
      "--------------------------------------------------------------------------------\n",
      "The colour? Ah, poor Tiny Tim!\n",
      "\n",
      "\"They're better now again,\" said Cratchit's wife.\n",
      "--------------------------------------------------------------------------------\n",
      "At last she said, and in a steady, cheerful\n",
      "voice, that only faltered once:\n",
      "\n",
      "\"I have known him walk with--I have known him walk with Tiny Tim upon\n",
      "his shoulder very fast indeed.\n",
      "--------------------------------------------------------------------------------\n",
      "It really seemed as if he had known our Tiny Tim, and felt\n",
      "with us.\n",
      "--------------------------------------------------------------------------------\n",
      "\"And I know,\" said Bob, \"I know, my dears, that when we recollect how\n",
      "patient and how mild he was, although he was a little, little child, we\n",
      "shall not quarrel easily among ourselves, and forget poor Tiny Tim in\n",
      "doing it.\n",
      "--------------------------------------------------------------------------------\n",
      "It's twice the\n",
      "size of Tiny Tim.\n",
      "--------------------------------------------------------------------------------\n",
      "He did it all, and infinitely more;\n",
      "and to Tiny Tim, who did NOT die, he was a second father.\n",
      "--------------------------------------------------------------------------------\n",
      "May that be truly said of us, and all of us! And so, as\n",
      "Tiny Tim observed, God bless Us, Every One!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End of the Project Gutenberg EBook of A Christmas Carol, by Charles Dickens\n",
      "\n",
      "*** END OF THIS PROJECT GUTENBERG EBOOK A CHRISTMAS CAROL ***\n",
      "\n",
      "***** This file should be named 19337-8.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sentence in get_sentence:\n",
    "    print(sentence.strip())\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
